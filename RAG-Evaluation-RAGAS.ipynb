{"cells":[{"attachments":{},"cell_type":"markdown","id":"aa1ba828-4960-4fde-a83a-081bc8e5a2d7","metadata":{"language":"python"},"source":"# RAG Evaluation with RAGAS"},{"attachments":{},"cell_type":"markdown","id":"4486e998-4736-49b4-b1e9-b31a36adc6ce","metadata":{"language":"python"},"source":"Ragas is an open-source framework that helps developers evaluate and test Large Language Model (LLM) applications, particularly Retrieval Augmented Generation (RAG) pipelines.\n\nRagas uses LLMs to measure key performance metrics, such as retrieved contexts, answer correctness, faithfullness, context relevancy, etc\n\nThis notebook shows how you can integrate their (RAGAS) excellent RAG metrics in LangSmith to evaluate your RAG app."},{"attachments":{},"cell_type":"markdown","id":"49e13d00-6df5-44f0-a598-6f54c8f7daed","metadata":{"language":"python"},"source":"## Prerequisites\nRagas and Langsmith\n\nLangSmith is a DevOps platform that helps developers and data scientists build, test, deploy, and monitor large language model (LLM) applications."},{"cell_type":"code","execution_count":4,"id":"cb55bf48-7f6e-4344-8f38-a33a783f9468","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:26:51.579357Z","iopub.status.busy":"2024-08-01T05:26:51.579032Z","iopub.status.idle":"2024-08-01T05:26:57.848128Z","shell.execute_reply":"2024-08-01T05:26:57.846065Z","shell.execute_reply.started":"2024-08-01T05:26:51.579322Z"},"language":"python","trusted":true},"outputs":[],"source":"%%capture --no-stderr\n%pip install -U langsmith ragas numpy openai"},{"cell_type":"code","execution_count":5,"id":"8d354501-a18a-491c-bff2-fd97339b7dae","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:27:10.510046Z","iopub.status.busy":"2024-08-01T05:27:10.509521Z","iopub.status.idle":"2024-08-01T05:27:22.201660Z","shell.execute_reply":"2024-08-01T05:27:22.201094Z","shell.execute_reply.started":"2024-08-01T05:27:10.510009Z"},"language":"python","trusted":true},"outputs":[{"name":"stdin","output_type":"stream","text":"LANGCHAIN_API_KEY ········\nOPENAI_API_KEY ········\n"}],"source":"import getpass\nimport os\n\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LANGCHAIN_API_KEY\")\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")"},{"attachments":{},"cell_type":"markdown","id":"512b79b9-d1ee-4fef-af52-8f6bd2ce2856","metadata":{"language":"python"},"source":"## Clone a Dataset to use"},{"cell_type":"code","execution_count":7,"id":"72984fa3-6e91-49f7-a7c2-87f4f59e45c9","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:28:08.454400Z","iopub.status.busy":"2024-08-01T05:28:08.453994Z","iopub.status.idle":"2024-08-01T05:28:09.658238Z","shell.execute_reply":"2024-08-01T05:28:09.657498Z","shell.execute_reply.started":"2024-08-01T05:28:08.454365Z"},"language":"python","trusted":true},"outputs":[],"source":"import langsmith\n\nclient = langsmith.Client()\ndataset_url = (\n    \"https://smith.langchain.com/public/56fe54cd-b7d7-4d3b-aaa0-88d7a2d30931/d\"\n)\ndataset_name = \"BaseCamp Q&A\"\nclient.clone_public_dataset(dataset_url)"},{"attachments":{},"cell_type":"markdown","id":"3dd36f0c-0c87-450f-9aa7-265fe55e8cc1","metadata":{"language":"python"},"source":"## Define your pipeline"},{"cell_type":"code","execution_count":8,"id":"7bb7cb56-b403-4672-a747-a8aea918439f","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:28:15.946574Z","iopub.status.busy":"2024-08-01T05:28:15.945927Z","iopub.status.idle":"2024-08-01T05:28:16.131226Z","shell.execute_reply":"2024-08-01T05:28:16.130684Z","shell.execute_reply.started":"2024-08-01T05:28:15.946534Z"},"language":"python","trusted":true},"outputs":[],"source":"import io\nimport os\nimport zipfile\n\nimport requests\n\n# Fetch the source documents\nurl = \"https://storage.googleapis.com/benchmarks-artifacts/basecamp-data/basecamp-data.zip\"\n\nresponse = requests.get(url)\n\n\nwith io.BytesIO(response.content) as zipped_file:\n    with zipfile.ZipFile(zipped_file, \"r\") as zip_ref:\n        zip_ref.extractall()\n\ndata_dir = os.path.join(os.getcwd(), \"data\")\ndocs = []\nfor filename in os.listdir(data_dir):\n    if filename.endswith(\".md\"):\n        with open(os.path.join(data_dir, filename), \"r\") as file:\n            docs.append({\"file\": filename, \"content\": file.read()})"},{"attachments":{},"cell_type":"markdown","id":"5bad76aa-b734-4407-a3a1-300df7337cd5","metadata":{"language":"python"},"source":"## Create the retriever"},{"cell_type":"code","execution_count":9,"id":"b2d07fe3-426d-4a9a-8081-97275acf5427","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:28:25.615239Z","iopub.status.busy":"2024-08-01T05:28:25.614820Z","iopub.status.idle":"2024-08-01T05:28:26.430082Z","shell.execute_reply":"2024-08-01T05:28:26.429405Z","shell.execute_reply.started":"2024-08-01T05:28:25.615210Z"},"language":"python","trusted":true},"outputs":[],"source":"from typing import List\n\nimport numpy as np\nimport openai\nfrom langsmith import traceable\n\n\nclass VectorStoreRetriever:\n    def __init__(self, docs: list, vectors: list, oai_client):\n        self._arr = np.array(vectors)\n        self._docs = docs\n        self._client = oai_client\n\n    @classmethod\n    async def from_docs(cls, docs, oai_client):\n        embeddings = await oai_client.embeddings.create(\n            model=\"text-embedding-3-small\", input=[doc[\"content\"] for doc in docs]\n        )\n        vectors = [emb.embedding for emb in embeddings.data]\n        return cls(docs, vectors, oai_client)\n\n    @traceable\n    async def query(self, query: str, k: int = 5) -> List[dict]:\n        embed = await self._client.embeddings.create(\n            model=\"text-embedding-3-small\", input=[query]\n        )\n        # \"@\" is just a matrix multiplication in python\n        scores = np.array(embed.data[0].embedding) @ self._arr.T\n        top_k_idx = np.argpartition(scores, -k)[-k:]\n        top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n        return [\n            {**self._docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n        ]"},{"cell_type":"code","execution_count":11,"id":"ca4c9d72-1726-4116-b572-f13ab1e802bd","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:28:37.312527Z","iopub.status.busy":"2024-08-01T05:28:37.312221Z","iopub.status.idle":"2024-08-01T05:28:37.320643Z","shell.execute_reply":"2024-08-01T05:28:37.319835Z","shell.execute_reply.started":"2024-08-01T05:28:37.312500Z"},"language":"python","trusted":true},"outputs":[],"source":"from langsmith import traceable\nfrom langsmith.wrappers import wrap_openai\n\n\nclass NaiveRagBot:\n    def __init__(self, retriever, model: str = \"gpt-4-turbo-preview\"):\n        self._retriever = retriever\n        # Wrapping the client instruments the LLM\n        # and is completely optional\n        self._client = wrap_openai(openai.AsyncClient())\n        self._model = model\n\n    @traceable\n    async def get_answer(self, question: str):\n        similar = await self._retriever.query(question)\n        response = await self._client.chat.completions.create(\n            model=self._model,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a helpful AI assistant.\"\n                    \" Use the following docs to help answer the user's question.\\n\\n\"\n                    f\"## Docs\\n\\n{similar}\",\n                },\n                {\"role\": \"user\", \"content\": question},\n            ],\n        )\n\n        # The RAGAS evaluators expect the \"answer\" and \"contexts\"\n        # keys to work properly. If your pipeline does not return these values,\n        # you should wrap in a function that provides them.\n        return {\n            \"answer\": response.choices[0].message.content,\n            \"contexts\": [str(doc) for doc in similar],\n        }"},{"cell_type":"code","execution_count":12,"id":"6cbfe564-e456-4b6b-9a8d-59dcf6c3b678","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:28:46.140241Z","iopub.status.busy":"2024-08-01T05:28:46.139850Z","iopub.status.idle":"2024-08-01T05:28:46.930643Z","shell.execute_reply":"2024-08-01T05:28:46.929938Z","shell.execute_reply.started":"2024-08-01T05:28:46.140202Z"},"language":"python","trusted":true},"outputs":[],"source":"retriever = await VectorStoreRetriever.from_docs(docs, openai.AsyncClient())\nrag_bot = NaiveRagBot(retriever)"},{"cell_type":"code","execution_count":13,"id":"5d4ec940-ef7c-4ac3-856d-c9719ca68c60","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:28:55.392065Z","iopub.status.busy":"2024-08-01T05:28:55.391673Z","iopub.status.idle":"2024-08-01T05:29:18.300096Z","shell.execute_reply":"2024-08-01T05:29:18.299291Z","shell.execute_reply.started":"2024-08-01T05:28:55.392030Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'Based on the information provided in the \"Benefits & Perks\" document, here is a summary of the time-off benefits at 37signals:\\n\\n### Paid Time Off (PTO'"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":"response = await rag_bot.get_answer(\"How much time off do we get?\")\nresponse[\"answer\"][:150]"},{"attachments":{},"cell_type":"markdown","id":"52cb63d5-366a-4329-b2a3-7102b1b69720","metadata":{"language":"python"},"source":"## Evaluate"},{"cell_type":"code","execution_count":23,"id":"210b86d4-7b62-4fc7-9a9a-8fe7828ac2c6","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:34:33.638041Z","iopub.status.busy":"2024-08-01T05:34:33.637550Z","iopub.status.idle":"2024-08-01T05:34:33.829079Z","shell.execute_reply":"2024-08-01T05:34:33.828224Z","shell.execute_reply.started":"2024-08-01T05:34:33.638013Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.smith import RunEvalConfig\nfrom ragas.integrations.langchain import EvaluatorChain\nfrom ragas.metrics import (\n    answer_correctness,\n    answer_relevancy,\n    context_precision,\n    context_recall,\n    faithfulness,\n)\n\n# Wrap the RAGAS metrics to use in LangChain\nevaluators = [\n    EvaluatorChain(metric)\n    for metric in [\n        answer_correctness,\n        answer_relevancy,\n        context_precision,\n        context_recall,\n        faithfulness,\n    ]\n]\neval_config = RunEvalConfig(custom_evaluators=evaluators)"},{"cell_type":"code","execution_count":25,"id":"968c40a0-e523-4fe9-beb8-ba73568072b6","metadata":{"execution":{"iopub.execute_input":"2024-08-01T05:34:56.561859Z","iopub.status.busy":"2024-08-01T05:34:56.561516Z","iopub.status.idle":"2024-08-01T05:41:42.934714Z","shell.execute_reply":"2024-08-01T05:41:42.934109Z","shell.execute_reply.started":"2024-08-01T05:34:56.561830Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"View the evaluation results for project 'diligent-tooth-31' at:\nhttps://smith.langchain.com/o/305dbe54-58db-588f-9847-6b70dc6ac00a/datasets/88c50c7b-003c-4b5e-bcb5-1544b2025b49/compare?selectedSessions=9493172a-2b33-49e2-bc42-5f260b626dce\n\nView all tests for Dataset BaseCamp Q&A at:\nhttps://smith.langchain.com/o/305dbe54-58db-588f-9847-6b70dc6ac00a/datasets/88c50c7b-003c-4b5e-bcb5-1544b2025b49\n[-------------------->                             ] 9/21"},{"name":"stderr","output_type":"stream","text":"Error evaluating run 487201ca-ebe6-4273-86ad-cc77b5cf9672 with EvaluatorChain: APIConnectionError('Connection error.')\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 1675, in send\n    raise exc\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 1669, in send\n    await response.aread()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 911, in aread\n    self._content = b\"\".join([part async for part in self.aiter_bytes()])\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 911, in <listcomp>\n    self._content = b\"\".join([part async for part in self.aiter_bytes()])\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 929, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 995, in aiter_raw\n    await self.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 1008, in aclose\n    await self.stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 155, in aclose\n    await self._stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_transports/default.py\", line 259, in aclose\n    await self._httpcore_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 380, in aclose\n    await self._pool._close_connections(closing)\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 305, in _close_connections\n    await connection.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 171, in aclose\n    await self._connection.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 265, in aclose\n    await self._network_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 55, in aclose\n    await self._stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/anyio/streams/tls.py\", line 195, in aclose\n    await self.transport_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1161, in aclose\n    self._transport.close()\n  File \"/opt/conda/lib/python3.11/asyncio/selector_events.py\", line 860, in close\n    self._loop.call_soon(self._call_connection_lost, None)\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 761, in call_soon\n    self._check_closed()\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 519, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 1675, in send\n    raise exc\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 1669, in send\n    await response.aread()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 911, in aread\n    self._content = b\"\".join([part async for part in self.aiter_bytes()])\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 911, in <listcomp>\n    self._content = b\"\".join([part async for part in self.aiter_bytes()])\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 929, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 995, in aiter_raw\n    await self.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 1008, in aclose\n    await self.stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 155, in aclose\n    await self._stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_transports/default.py\", line 259, in aclose\n    await self._httpcore_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 380, in aclose\n    await self._pool._close_connections(closing)\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 305, in _close_connections\n    await connection.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 171, in aclose\n    await self._connection.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 265, in aclose\n    await self._network_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 55, in aclose\n    await self._stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/anyio/streams/tls.py\", line 195, in aclose\n    await self.transport_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1161, in aclose\n    self._transport.close()\n  File \"/opt/conda/lib/python3.11/asyncio/selector_events.py\", line 860, in close\n    self._loop.call_soon(self._call_connection_lost, None)\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 761, in call_soon\n    self._check_closed()\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 519, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 1675, in send\n    raise exc\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 1669, in send\n    await response.aread()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 911, in aread\n    self._content = b\"\".join([part async for part in self.aiter_bytes()])\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 911, in <listcomp>\n    self._content = b\"\".join([part async for part in self.aiter_bytes()])\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 929, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 995, in aiter_raw\n    await self.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_models.py\", line 1008, in aclose\n    await self.stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_client.py\", line 155, in aclose\n    await self._stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpx/_transports/default.py\", line 259, in aclose\n    await self._httpcore_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 380, in aclose\n    await self._pool._close_connections(closing)\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 305, in _close_connections\n    await connection.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 171, in aclose\n    await self._connection.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 265, in aclose\n    await self._network_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 55, in aclose\n    await self._stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/anyio/streams/tls.py\", line 195, in aclose\n    await self.transport_stream.aclose()\n  File \"/opt/conda/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1161, in aclose\n    self._transport.close()\n  File \"/opt/conda/lib/python3.11/asyncio/selector_events.py\", line 860, in close\n    self._loop.call_soon(self._call_connection_lost, None)\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 761, in call_soon\n    self._check_closed()\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 519, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/tracers/evaluation.py\", line 127, in _evaluate_in_project\n    evaluation_result = evaluator.evaluate_run(\n                        ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/integrations/langchain.py\", line 210, in evaluate_run\n    eval_output = self.invoke(chain_eval, include_run_info=True)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py\", line 166, in invoke\n    raise e\n  File \"/opt/conda/lib/python3.11/site-packages/langchain/chains/base.py\", line 156, in invoke\n    self._call(inputs, run_manager=run_manager)\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/integrations/langchain.py\", line 80, in _call\n    score = self.metric.score(\n            ^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/metrics/base.py\", line 105, in score\n    raise e\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/metrics/base.py\", line 101, in score\n    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/asyncio/runners.py\", line 190, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/metrics/_faithfulness.py\", line 246, in _ascore\n    statements = await self.llm.generate(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/llms/base.py\", line 95, in generate\n    return await agenerate_text_with_retry(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n    return await copy(fn, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n    do = await self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/opt/conda/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n    result = await fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ragas/llms/base.py\", line 176, in agenerate_text\n    return await self.langchain_llm.agenerate_prompt(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 724, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 684, in agenerate\n    raise exceptions[0]\n  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 883, in _agenerate_with_cache\n    result = await self._agenerate(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 752, in _agenerate\n    response = await self.async_client.create(**payload)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1295, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1582, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1651, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1582, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1651, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1592, in _request\n    raise APIConnectionError(request=request) from err\nopenai.APIConnectionError: Connection error.\nError in EvaluatorCallbackHandler.on_chain_end callback: APIConnectionError('Connection error.')\n"},{"name":"stdout","output_type":"stream","text":"[------------------------------------------------->] 21/21"}],"source":"results = await client.arun_on_dataset(\n    dataset_name=dataset_name,\n    llm_or_chain_factory=rag_bot.get_answer,\n    evaluation=eval_config,\n)"},{"cell_type":"code","execution_count":null,"id":"9a5b0393-3ea0-4734-b5c4-87748dee2255","metadata":{"language":"python","trusted":true},"outputs":[],"source":""}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"a22b6f8b-b11b-4979-98da-98513e9876e6","defaultDatabase":""},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}